{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN7j2KbK8vgolNX8GnBBrT1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ak2742/mlplay/blob/Fine-Tuning/10)_Tagging_with_ollama_llama3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Install package and load the extension\n",
        "!pip install colab-xterm\n",
        "%load_ext colabxterm\n",
        "%xterm\n",
        "\n",
        "# #- Install/run Ollama in terminal\n",
        "\n",
        "# !curl -fsSL https://ollama.com/install.sh | sh\n",
        "# !ollama serve & ollama pull llama3"
      ],
      "metadata": {
        "id": "C99IPN_LY-jZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tItATjLXHnKu"
      },
      "outputs": [],
      "source": [
        "#@title Install libraries\n",
        "\n",
        "#LangChain related libraries\n",
        "!pip install -q -U langchain==0.1.20 langchain_experimental"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title tagging config\n",
        "\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.pydantic_v1 import BaseModel, Field\n",
        "\n",
        "# tagging prompt template\n",
        "tagging_prompt = ChatPromptTemplate.from_template(\n",
        "\"\"\"\n",
        "Extract the desired information from the  passage given in triple Backticks.\n",
        "\n",
        "Only extract the properties mentioned in the 'Classification' function.\n",
        "\n",
        "Please follow the response format as given.\n",
        "\n",
        "Passage:\n",
        "'''{input}'''\n",
        "\"\"\"\n",
        ")\n",
        "\n",
        "# Output Schema for structured response\n",
        "class Classification(BaseModel):\n",
        "    sentiment: str = Field(description=\"The sentiment of the text. \\\n",
        "                           If no sentiment is detected, the value is 'Neutral'\", enum=[\"happy\", \"neutral\", \"sad\"])\n",
        "    aggressiveness: int = Field(\n",
        "        description=\"How aggressive the text is on a scale from 1 to 10. \\\n",
        "            If no aggressiveness is detected, the value is 1\"\n",
        "    )\n",
        "    language: str = Field(description=\"The language the text is written in \\\n",
        "            If unknown language, the value is 'Unknown'\")\n"
      ],
      "metadata": {
        "id": "P3__zrBQJeFa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Create Chain with llama3\n",
        "\n",
        "from langchain_experimental.llms.ollama_functions import OllamaFunctions\n",
        "\n",
        "# Chain\n",
        "llm = OllamaFunctions(model=\"llama3\", format=\"json\", temperature=0)\n",
        "structured_llm = llm.with_structured_output(Classification)\n",
        "chain = tagging_prompt | structured_llm"
      ],
      "metadata": {
        "id": "OxdAumJ8N1N7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Get response in json format\n",
        "\n",
        "inp = \"Estoy increiblemente contento de haberte conocido! Creo que seremos muy buenos amigos!\"\n",
        "res = chain.invoke({\"input\": inp}).dict()\n",
        "res"
      ],
      "metadata": {
        "id": "EqfjAPE4LEgj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}